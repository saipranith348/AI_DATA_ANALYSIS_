{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring Consistency Across Training & Inference Datasets: Feature Scaling\n",
    "**Question**: Load a dataset (e.g., Boston Housing) and perform feature scaling. Ensure the\n",
    "same scaling is applied during model inference with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### Ensuring Consistency Across Training & Inference Datasets: Feature Scaling\\n',\n",
       "    '**Question**: Load a dataset (e.g., Boston Housing) and perform feature scaling. Ensure the\\n',\n",
       "    'same scaling is applied during model inference with new data.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 1,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['Predicted Median House Value: 4.15\\n']}],\n",
       "   'source': ['# write your code from here\\n',\n",
       "    '# --- Step 1: Import Required Libraries ---\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'from sklearn.datasets import fetch_california_housing\\n',\n",
       "    'from sklearn.model_selection import train_test_split\\n',\n",
       "    'from sklearn.preprocessing import StandardScaler\\n',\n",
       "    'from sklearn.linear_model import LinearRegression\\n',\n",
       "    'import joblib\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 2: Load Dataset with Error Handling ---\\n',\n",
       "    'def load_data():\\n',\n",
       "    '    try:\\n',\n",
       "    '        data = fetch_california_housing()\\n',\n",
       "    '        X = pd.DataFrame(data.data, columns=data.feature_names)\\n',\n",
       "    '        y = pd.Series(data.target, name=\"MedHouseValue\")\\n',\n",
       "    '        return X, y\\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"Error loading dataset: {e}\")\\n',\n",
       "    '        return pd.DataFrame(), pd.Series()\\n',\n",
       "    '\\n',\n",
       "    'X, y = load_data()\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 3: Check for Missing Values ---\\n',\n",
       "    'if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\\n',\n",
       "    '    print(\"Missing values found. Handling them...\")\\n',\n",
       "    '    X.fillna(X.mean(), inplace=True)\\n',\n",
       "    '    y.fillna(y.mean(), inplace=True)\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 4: Train-Test Split ---\\n',\n",
       "    'try:\\n',\n",
       "    '    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n',\n",
       "    'except ValueError as e:\\n',\n",
       "    '    print(f\"Error in train-test split: {e}\")\\n',\n",
       "    '    X_train = X_test = y_train = y_test = pd.DataFrame()\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 5: Feature Scaling with Error Handling ---\\n',\n",
       "    'scaler = StandardScaler()\\n',\n",
       "    'try:\\n',\n",
       "    '    X_train_scaled = scaler.fit_transform(X_train)\\n',\n",
       "    '    X_test_scaled = scaler.transform(X_test)\\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"Error during scaling: {e}\")\\n',\n",
       "    '    X_train_scaled = X_test_scaled = np.array([])\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 6: Train Model ---\\n',\n",
       "    'model = LinearRegression()\\n',\n",
       "    'try:\\n',\n",
       "    '    model.fit(X_train_scaled, y_train)\\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"Error training model: {e}\")\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 7: Inference on New Data (Simulate One Row) ---\\n',\n",
       "    'def predict_new_data(new_data):\\n',\n",
       "    '    try:\\n',\n",
       "    '        if new_data.isnull().sum().sum() > 0:\\n',\n",
       "    '            print(\"New data has missing values. Filling with mean.\")\\n',\n",
       "    '            new_data.fillna(X.mean(), inplace=True)\\n',\n",
       "    '        new_data_scaled = scaler.transform(new_data)\\n',\n",
       "    '        prediction = model.predict(new_data_scaled)\\n',\n",
       "    '        return prediction[0]\\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"Prediction error: {e}\")\\n',\n",
       "    '        return None\\n',\n",
       "    '\\n',\n",
       "    'new_data = X.iloc[[0]]  # simulate one new data row\\n',\n",
       "    'predicted_value = predict_new_data(new_data)\\n',\n",
       "    '\\n',\n",
       "    'if predicted_value is not None:\\n',\n",
       "    '    print(f\"Predicted Median House Value: {predicted_value:.2f}\")\\n',\n",
       "    '\\n',\n",
       "    '# --- Step 8: Save Model & Scaler ---\\n',\n",
       "    'try:\\n',\n",
       "    \"    joblib.dump(model, 'california_model.pkl')\\n\",\n",
       "    \"    joblib.dump(scaler, 'california_scaler.pkl')\\n\",\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"Error saving model or scaler: {e}\")']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.10.12'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Ensuring Consistency Across Training & Inference Datasets: Feature Scaling\\n\",\n",
    "    \"**Question**: Load a dataset (e.g., Boston Housing) and perform feature scaling. Ensure the\\n\",\n",
    "    \"same scaling is applied during model inference with new data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Predicted Median House Value: 4.15\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# write your code from here\\n\",\n",
    "    \"# --- Step 1: Import Required Libraries ---\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sklearn.datasets import fetch_california_housing\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 2: Load Dataset with Error Handling ---\\n\",\n",
    "    \"def load_data():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        data = fetch_california_housing()\\n\",\n",
    "    \"        X = pd.DataFrame(data.data, columns=data.feature_names)\\n\",\n",
    "    \"        y = pd.Series(data.target, name=\\\"MedHouseValue\\\")\\n\",\n",
    "    \"        return X, y\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error loading dataset: {e}\\\")\\n\",\n",
    "    \"        return pd.DataFrame(), pd.Series()\\n\",\n",
    "    \"\\n\",\n",
    "    \"X, y = load_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 3: Check for Missing Values ---\\n\",\n",
    "    \"if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\\n\",\n",
    "    \"    print(\\\"Missing values found. Handling them...\\\")\\n\",\n",
    "    \"    X.fillna(X.mean(), inplace=True)\\n\",\n",
    "    \"    y.fillna(y.mean(), inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 4: Train-Test Split ---\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
    "    \"except ValueError as e:\\n\",\n",
    "    \"    print(f\\\"Error in train-test split: {e}\\\")\\n\",\n",
    "    \"    X_train = X_test = y_train = y_test = pd.DataFrame()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 5: Feature Scaling with Error Handling ---\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"    X_test_scaled = scaler.transform(X_test)\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error during scaling: {e}\\\")\\n\",\n",
    "    \"    X_train_scaled = X_test_scaled = np.array([])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 6: Train Model ---\\n\",\n",
    "    \"model = LinearRegression()\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error training model: {e}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 7: Inference on New Data (Simulate One Row) ---\\n\",\n",
    "    \"def predict_new_data(new_data):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        if new_data.isnull().sum().sum() > 0:\\n\",\n",
    "    \"            print(\\\"New data has missing values. Filling with mean.\\\")\\n\",\n",
    "    \"            new_data.fillna(X.mean(), inplace=True)\\n\",\n",
    "    \"        new_data_scaled = scaler.transform(new_data)\\n\",\n",
    "    \"        prediction = model.predict(new_data_scaled)\\n\",\n",
    "    \"        return prediction[0]\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Prediction error: {e}\\\")\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"new_data = X.iloc[[0]]  # simulate one new data row\\n\",\n",
    "    \"predicted_value = predict_new_data(new_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if predicted_value is not None:\\n\",\n",
    "    \"    print(f\\\"Predicted Median House Value: {predicted_value:.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Step 8: Save Model & Scaler ---\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    joblib.dump(model, 'california_model.pkl')\\n\",\n",
    "    \"    joblib.dump(scaler, 'california_scaler.pkl')\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error saving model or scaler: {e}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
