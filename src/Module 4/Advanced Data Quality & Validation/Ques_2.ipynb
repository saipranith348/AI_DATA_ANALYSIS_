{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': 6,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['Data Drift Detection Results:\\n',\n",
       "      'Age: No Drift\\n',\n",
       "      'Salary: No Drift\\n',\n",
       "      '\\n',\n",
       "      'Data Quality Checks Results:\\n',\n",
       "      'Missing Values: Series([], dtype: int64)\\n',\n",
       "      'Duplicates: 0\\n',\n",
       "      'Outliers: 0\\n']}],\n",
       "   'source': ['import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    'from scipy.stats import ks_2samp\\n',\n",
       "    '\\n',\n",
       "    '# Sample data for training and current dataset\\n',\n",
       "    'train_data = {\\n',\n",
       "    \"    'Age': [25, 30, 35, 40, 45, 50, 55],\\n\",\n",
       "    \"    'Salary': [50000, 60000, 70000, 80000, 90000, 100000, 110000]\\n\",\n",
       "    '}\\n',\n",
       "    '\\n',\n",
       "    'current_data = {\\n',\n",
       "    \"    'Age': [26, 31, 36, 41, 46, 51, 60],\\n\",\n",
       "    \"    'Salary': [51000, 61000, 71000, 81000, 91000, 101000, 105000]\\n\",\n",
       "    '}\\n',\n",
       "    '\\n',\n",
       "    'train_df = pd.DataFrame(train_data)\\n',\n",
       "    'current_df = pd.DataFrame(current_data)\\n',\n",
       "    '\\n',\n",
       "    '# Step 1: Detect Data Drift using KS-test (Kolmogorov-Smirnov test)\\n',\n",
       "    'def detect_data_drift(train_df, current_df):\\n',\n",
       "    '    drift_results = {}\\n',\n",
       "    '    \\n',\n",
       "    '    # Loop through columns in the training data\\n',\n",
       "    '    for column in train_df.columns:\\n',\n",
       "    '        # Perform KS-test to compare distributions of train and current data\\n',\n",
       "    '        statistic, p_value = ks_2samp(train_df[column], current_df[column])\\n',\n",
       "    '        \\n',\n",
       "    '        # If p_value < 0.05, it indicates significant drift\\n',\n",
       "    '        drift_results[column] = \"Drift Detected\" if p_value < 0.05 else \"No Drift\"\\n',\n",
       "    '    \\n',\n",
       "    '    return drift_results\\n',\n",
       "    '\\n',\n",
       "    '# Step 2: Data Quality Checks\\n',\n",
       "    'def data_quality_checks(df):\\n',\n",
       "    '    quality_issues = {}\\n',\n",
       "    '    \\n',\n",
       "    '    # Check for missing values\\n',\n",
       "    '    missing_values = df.isnull().sum()\\n',\n",
       "    \"    quality_issues['Missing Values'] = missing_values[missing_values > 0]\\n\",\n",
       "    '    \\n',\n",
       "    '    # Check for duplicate rows\\n',\n",
       "    '    duplicates = df.duplicated().sum()\\n',\n",
       "    \"    quality_issues['Duplicates'] = duplicates\\n\",\n",
       "    '    \\n',\n",
       "    '    # Check for outliers using Z-score\\n',\n",
       "    '    z_scores = np.abs((df - df.mean()) / df.std())\\n',\n",
       "    '    outliers = (z_scores > 3).sum()\\n',\n",
       "    \"    quality_issues['Outliers'] = outliers.sum()\\n\",\n",
       "    '    \\n',\n",
       "    '    return quality_issues\\n',\n",
       "    '\\n',\n",
       "    '# Step 3: Visualize the Drift (Optional)\\n',\n",
       "    'def visualize_drift(train_df, current_df):\\n',\n",
       "    '    # Visualize histograms for each column to compare distributions\\n',\n",
       "    '    for column in train_df.columns:\\n',\n",
       "    '        plt.figure(figsize=(10, 6))\\n',\n",
       "    \"        sns.histplot(train_df[column], color='blue', label='Training Data', kde=True, stat='density', linewidth=0)\\n\",\n",
       "    \"        sns.histplot(current_df[column], color='red', label='Current Data', kde=True, stat='density', linewidth=0)\\n\",\n",
       "    \"        plt.title(f'Distribution Comparison for {column}')\\n\",\n",
       "    '        plt.legend()\\n',\n",
       "    '        plt.show()\\n',\n",
       "    '\\n',\n",
       "    '# Step 4: Execute Drift Detection and Data Quality Checks\\n',\n",
       "    'drift_results = detect_data_drift(train_df, current_df)\\n',\n",
       "    'quality_issues = data_quality_checks(current_df)\\n',\n",
       "    '\\n',\n",
       "    '# Display the results\\n',\n",
       "    'print(\"Data Drift Detection Results:\")\\n',\n",
       "    'for feature, drift in drift_results.items():\\n',\n",
       "    '    print(f\"{feature}: {drift}\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nData Quality Checks Results:\")\\n',\n",
       "    'for issue, count in quality_issues.items():\\n',\n",
       "    '    print(f\"{issue}: {count}\")\\n',\n",
       "    '\\n',\n",
       "    '# Visualize Drift\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '# Optimized version of data quality checks with better error handling and vectorization\\n',\n",
       "    'def data_quality_checks_optimized(df):\\n',\n",
       "    '    quality_issues = {}\\n',\n",
       "    '    \\n',\n",
       "    '    # Check for missing values - vectorized operation\\n',\n",
       "    '    missing_values = df.isnull().sum()\\n',\n",
       "    '    if missing_values.any():\\n',\n",
       "    \"        quality_issues['Missing Values'] = missing_values[missing_values > 0]\\n\",\n",
       "    '    \\n',\n",
       "    '    # Check for duplicate rows - efficient without looping\\n',\n",
       "    '    duplicates = df.duplicated().sum()\\n',\n",
       "    '    if duplicates > 0:\\n',\n",
       "    \"        quality_issues['Duplicates'] = duplicates\\n\",\n",
       "    '    \\n',\n",
       "    '    # Outlier detection using vectorized z-score calculation\\n',\n",
       "    '    z_scores = np.abs((df.select_dtypes(include=[np.number]) - df.mean()) / df.std())\\n',\n",
       "    '    outliers = (z_scores > 3).sum()  # count the number of outliers\\n',\n",
       "    '    if outliers.any():\\n',\n",
       "    \"        quality_issues['Outliers'] = outliers.sum()\\n\",\n",
       "    '    \\n',\n",
       "    '    # Return collected quality issues\\n',\n",
       "    '    return quality_issues\\n',\n",
       "    '\\n',\n",
       "    '# Error handling when performing KS-test for drift detection\\n',\n",
       "    'def safe_ks_test(train_series, current_series):\\n',\n",
       "    '    try:\\n',\n",
       "    '        statistic, p_value = ks_2samp(train_series, current_series)\\n',\n",
       "    '        return statistic, p_value\\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"Error in KS-test for columns: {e}\")\\n',\n",
       "    '        return None, None\\n',\n",
       "    '\\n',\n",
       "    '# Example of applying the error-safe KS-test for drift detection\\n',\n",
       "    'def detect_data_drift_with_error_handling(train_df, current_df):\\n',\n",
       "    '    drift_results = {}\\n',\n",
       "    '    for column in train_df.columns:\\n',\n",
       "    '        if column in current_df.columns:\\n',\n",
       "    '            statistic, p_value = safe_ks_test(train_df[column], current_df[column])\\n',\n",
       "    '            if p_value is not None:\\n',\n",
       "    '                drift_results[column] = \"Drift Detected\" if p_value < 0.05 else \"No Drift\"\\n',\n",
       "    '        else:\\n',\n",
       "    '            drift_results[column] = \"Column missing in current data\"\\n',\n",
       "    '    \\n',\n",
       "    '    return drift_results']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.10.12'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Data Drift Detection Results:\\n\",\n",
    "      \"Age: No Drift\\n\",\n",
    "      \"Salary: No Drift\\n\",\n",
    "      \"\\n\",\n",
    "      \"Data Quality Checks Results:\\n\",\n",
    "      \"Missing Values: Series([], dtype: int64)\\n\",\n",
    "      \"Duplicates: 0\\n\",\n",
    "      \"Outliers: 0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from scipy.stats import ks_2samp\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample data for training and current dataset\\n\",\n",
    "    \"train_data = {\\n\",\n",
    "    \"    'Age': [25, 30, 35, 40, 45, 50, 55],\\n\",\n",
    "    \"    'Salary': [50000, 60000, 70000, 80000, 90000, 100000, 110000]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"current_data = {\\n\",\n",
    "    \"    'Age': [26, 31, 36, 41, 46, 51, 60],\\n\",\n",
    "    \"    'Salary': [51000, 61000, 71000, 81000, 91000, 101000, 105000]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_df = pd.DataFrame(train_data)\\n\",\n",
    "    \"current_df = pd.DataFrame(current_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 1: Detect Data Drift using KS-test (Kolmogorov-Smirnov test)\\n\",\n",
    "    \"def detect_data_drift(train_df, current_df):\\n\",\n",
    "    \"    drift_results = {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loop through columns in the training data\\n\",\n",
    "    \"    for column in train_df.columns:\\n\",\n",
    "    \"        # Perform KS-test to compare distributions of train and current data\\n\",\n",
    "    \"        statistic, p_value = ks_2samp(train_df[column], current_df[column])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # If p_value < 0.05, it indicates significant drift\\n\",\n",
    "    \"        drift_results[column] = \\\"Drift Detected\\\" if p_value < 0.05 else \\\"No Drift\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return drift_results\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 2: Data Quality Checks\\n\",\n",
    "    \"def data_quality_checks(df):\\n\",\n",
    "    \"    quality_issues = {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for missing values\\n\",\n",
    "    \"    missing_values = df.isnull().sum()\\n\",\n",
    "    \"    quality_issues['Missing Values'] = missing_values[missing_values > 0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for duplicate rows\\n\",\n",
    "    \"    duplicates = df.duplicated().sum()\\n\",\n",
    "    \"    quality_issues['Duplicates'] = duplicates\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for outliers using Z-score\\n\",\n",
    "    \"    z_scores = np.abs((df - df.mean()) / df.std())\\n\",\n",
    "    \"    outliers = (z_scores > 3).sum()\\n\",\n",
    "    \"    quality_issues['Outliers'] = outliers.sum()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return quality_issues\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 3: Visualize the Drift (Optional)\\n\",\n",
    "    \"def visualize_drift(train_df, current_df):\\n\",\n",
    "    \"    # Visualize histograms for each column to compare distributions\\n\",\n",
    "    \"    for column in train_df.columns:\\n\",\n",
    "    \"        plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"        sns.histplot(train_df[column], color='blue', label='Training Data', kde=True, stat='density', linewidth=0)\\n\",\n",
    "    \"        sns.histplot(current_df[column], color='red', label='Current Data', kde=True, stat='density', linewidth=0)\\n\",\n",
    "    \"        plt.title(f'Distribution Comparison for {column}')\\n\",\n",
    "    \"        plt.legend()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 4: Execute Drift Detection and Data Quality Checks\\n\",\n",
    "    \"drift_results = detect_data_drift(train_df, current_df)\\n\",\n",
    "    \"quality_issues = data_quality_checks(current_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display the results\\n\",\n",
    "    \"print(\\\"Data Drift Detection Results:\\\")\\n\",\n",
    "    \"for feature, drift in drift_results.items():\\n\",\n",
    "    \"    print(f\\\"{feature}: {drift}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nData Quality Checks Results:\\\")\\n\",\n",
    "    \"for issue, count in quality_issues.items():\\n\",\n",
    "    \"    print(f\\\"{issue}: {count}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize Drift\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optimized version of data quality checks with better error handling and vectorization\\n\",\n",
    "    \"def data_quality_checks_optimized(df):\\n\",\n",
    "    \"    quality_issues = {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for missing values - vectorized operation\\n\",\n",
    "    \"    missing_values = df.isnull().sum()\\n\",\n",
    "    \"    if missing_values.any():\\n\",\n",
    "    \"        quality_issues['Missing Values'] = missing_values[missing_values > 0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for duplicate rows - efficient without looping\\n\",\n",
    "    \"    duplicates = df.duplicated().sum()\\n\",\n",
    "    \"    if duplicates > 0:\\n\",\n",
    "    \"        quality_issues['Duplicates'] = duplicates\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Outlier detection using vectorized z-score calculation\\n\",\n",
    "    \"    z_scores = np.abs((df.select_dtypes(include=[np.number]) - df.mean()) / df.std())\\n\",\n",
    "    \"    outliers = (z_scores > 3).sum()  # count the number of outliers\\n\",\n",
    "    \"    if outliers.any():\\n\",\n",
    "    \"        quality_issues['Outliers'] = outliers.sum()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Return collected quality issues\\n\",\n",
    "    \"    return quality_issues\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Error handling when performing KS-test for drift detection\\n\",\n",
    "    \"def safe_ks_test(train_series, current_series):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        statistic, p_value = ks_2samp(train_series, current_series)\\n\",\n",
    "    \"        return statistic, p_value\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error in KS-test for columns: {e}\\\")\\n\",\n",
    "    \"        return None, None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Example of applying the error-safe KS-test for drift detection\\n\",\n",
    "    \"def detect_data_drift_with_error_handling(train_df, current_df):\\n\",\n",
    "    \"    drift_results = {}\\n\",\n",
    "    \"    for column in train_df.columns:\\n\",\n",
    "    \"        if column in current_df.columns:\\n\",\n",
    "    \"            statistic, p_value = safe_ks_test(train_df[column], current_df[column])\\n\",\n",
    "    \"            if p_value is not None:\\n\",\n",
    "    \"                drift_results[column] = \\\"Drift Detected\\\" if p_value < 0.05 else \\\"No Drift\\\"\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            drift_results[column] = \\\"Column missing in current data\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return drift_results\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Automating Data Quality Checks\n",
    "# Objective: Use Python and data quality frameworks to automate validation.\n",
    "\n",
    "# Task 1: Setting Up Automated Validation with Python\n",
    "\n",
    "# Task 2: Introduction to Great Expectations: Install the great_expectations package and set up a basic project.\n",
    "\n",
    "# Task 3: Creating Expectations with Great Expectations: Use Great Expectations to define data validation expectations for a dataset.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
