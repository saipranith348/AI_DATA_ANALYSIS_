{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['    Task: Complete Pipeline for a Dataset\\n',\n",
       "    '1. Objective: Build a complex pipeline with multiple transformations.\\n',\n",
       "    '2. Steps:\\n',\n",
       "    '    - Load a sample dataset.\\n',\n",
       "    '    - Define a transformation pipeline with both imputation and scaling.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 2,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['Defaulting to user installation because normal site-packages is not writeable\\n',\n",
       "      'Requirement already satisfied: pytest in /home/vscode/.local/lib/python3.10/site-packages (8.3.5)\\n',\n",
       "      'Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (1.2.2)\\n',\n",
       "      'Requirement already satisfied: iniconfig in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (2.1.0)\\n',\n",
       "      'Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (25.0)\\n',\n",
       "      'Requirement already satisfied: pluggy<2,>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (1.6.0)\\n',\n",
       "      'Requirement already satisfied: tomli>=1 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (2.2.1)\\n',\n",
       "      'Note: you may need to restart the kernel to use updated packages.\\n']}],\n",
       "   'source': ['pip install pytest\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Task: Imputation Function\\n',\n",
       "    '\\n',\n",
       "    'import pytest\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'from sklearn.impute import SimpleImputer\\n',\n",
       "    'from sklearn.preprocessing import StandardScaler\\n',\n",
       "    '\\n',\n",
       "    '# Test for Imputation\\n',\n",
       "    'def test_imputation():\\n',\n",
       "    '    # Sample data with missing values\\n',\n",
       "    \"    data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]}\\n\",\n",
       "    '    df = pd.DataFrame(data)\\n',\n",
       "    '    \\n',\n",
       "    \"    imputer = SimpleImputer(strategy='mean')\\n\",\n",
       "    '    imputed_data = imputer.fit_transform(df)\\n',\n",
       "    '    \\n',\n",
       "    '    # Assert that missing values are replaced\\n',\n",
       "    '    assert not np.any(np.isnan(imputed_data)), \"Missing values exist after imputation!\"\\n',\n",
       "    '\\n',\n",
       "    '# Test for Scaling\\n',\n",
       "    'def test_scaling():\\n',\n",
       "    '    # Sample data\\n',\n",
       "    \"    data = {'A': [1, 2, 3, 4], 'B': [5, 6, 7, 8]}\\n\",\n",
       "    '    df = pd.DataFrame(data)\\n',\n",
       "    '    \\n',\n",
       "    '    scaler = StandardScaler()\\n',\n",
       "    '    scaled_data = scaler.fit_transform(df)\\n',\n",
       "    '    \\n',\n",
       "    '    # Assert that the scaled data has mean=0 and std=1 for each column\\n',\n",
       "    '    assert np.abs(np.mean(scaled_data[:, 0])) < 0.1, \"Column A mean is not close to 0\"  # Column A\\n',\n",
       "    '    assert np.abs(np.mean(scaled_data[:, 1])) < 0.1, \"Column B mean is not close to 0\"  # Column B\\n',\n",
       "    '    assert np.abs(np.std(scaled_data[:, 0]) - 1) < 0.1, \"Column A std is not close to 1\"\\n',\n",
       "    '    assert np.abs(np.std(scaled_data[:, 1]) - 1) < 0.1, \"Column B std is not close to 1\"\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '# Scaling Function\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '# Combined Transformation Function\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 4,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['          A         B\\n',\n",
       "      '0 -1.147079 -1.605910\\n',\n",
       "      '1 -0.229416  0.229416\\n',\n",
       "      '2 -0.229416  0.229416\\n',\n",
       "      '3  1.605910  1.147079\\n']},\n",
       "    {'name': 'stderr',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['/tmp/ipykernel_11771/3361112369.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\\n',\n",
       "      '  if not np.issubdtype(df.dtypes[0], np.number):  # Check if data is numeric\\n']}],\n",
       "   'source': ['import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'from sklearn.preprocessing import StandardScaler\\n',\n",
       "    'from sklearn.impute import SimpleImputer\\n',\n",
       "    '\\n',\n",
       "    '# Imputation Function\\n',\n",
       "    \"def impute_data(df, strategy='mean'):\\n\",\n",
       "    '    for column in df.columns:\\n',\n",
       "    '        if df[column].isna().sum() == len(df):\\n',\n",
       "    '            df[column] = 0  # Or replace with df[column].median() or another placeholder\\n',\n",
       "    '    imputer = SimpleImputer(strategy=strategy)\\n',\n",
       "    '    return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\\n',\n",
       "    '\\n',\n",
       "    '# Scaling Function\\n',\n",
       "    'def scale_data(df):\\n',\n",
       "    '    scaler = StandardScaler()\\n',\n",
       "    '    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n',\n",
       "    '\\n',\n",
       "    '# DataFrame Validation Function\\n',\n",
       "    'def validate_dataframe(df):\\n',\n",
       "    '    if df.empty:\\n',\n",
       "    '        raise ValueError(\"DataFrame is empty\")\\n',\n",
       "    '    if not np.issubdtype(df.dtypes[0], np.number):  # Check if data is numeric\\n',\n",
       "    '        raise TypeError(\"DataFrame contains non-numeric data. Only numeric data is allowed.\")\\n',\n",
       "    '\\n',\n",
       "    '# Combined Transformation Function\\n',\n",
       "    \"def transform_data(df, imputation_strategy='mean'):\\n\",\n",
       "    '    validate_dataframe(df)\\n',\n",
       "    '    df = impute_data(df, strategy=imputation_strategy)\\n',\n",
       "    '    df = scale_data(df)\\n',\n",
       "    '    return df\\n',\n",
       "    '\\n',\n",
       "    '# Example Usage\\n',\n",
       "    \"data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]}\\n\",\n",
       "    'df = pd.DataFrame(data)\\n',\n",
       "    '\\n',\n",
       "    \"transformed_df = transform_data(df, imputation_strategy='median')\\n\",\n",
       "    'print(transformed_df)']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.10.12'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Task: Complete Pipeline for a Dataset\\n\",\n",
    "    \"1. Objective: Build a complex pipeline with multiple transformations.\\n\",\n",
    "    \"2. Steps:\\n\",\n",
    "    \"    - Load a sample dataset.\\n\",\n",
    "    \"    - Define a transformation pipeline with both imputation and scaling.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Defaulting to user installation because normal site-packages is not writeable\\n\",\n",
    "      \"Requirement already satisfied: pytest in /home/vscode/.local/lib/python3.10/site-packages (8.3.5)\\n\",\n",
    "      \"Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (1.2.2)\\n\",\n",
    "      \"Requirement already satisfied: iniconfig in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (2.1.0)\\n\",\n",
    "      \"Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (25.0)\\n\",\n",
    "      \"Requirement already satisfied: pluggy<2,>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (1.6.0)\\n\",\n",
    "      \"Requirement already satisfied: tomli>=1 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (2.2.1)\\n\",\n",
    "      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"pip install pytest\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Task: Imputation Function\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pytest\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test for Imputation\\n\",\n",
    "    \"def test_imputation():\\n\",\n",
    "    \"    # Sample data with missing values\\n\",\n",
    "    \"    data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]}\\n\",\n",
    "    \"    df = pd.DataFrame(data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    imputer = SimpleImputer(strategy='mean')\\n\",\n",
    "    \"    imputed_data = imputer.fit_transform(df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Assert that missing values are replaced\\n\",\n",
    "    \"    assert not np.any(np.isnan(imputed_data)), \\\"Missing values exist after imputation!\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test for Scaling\\n\",\n",
    "    \"def test_scaling():\\n\",\n",
    "    \"    # Sample data\\n\",\n",
    "    \"    data = {'A': [1, 2, 3, 4], 'B': [5, 6, 7, 8]}\\n\",\n",
    "    \"    df = pd.DataFrame(data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    scaler = StandardScaler()\\n\",\n",
    "    \"    scaled_data = scaler.fit_transform(df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Assert that the scaled data has mean=0 and std=1 for each column\\n\",\n",
    "    \"    assert np.abs(np.mean(scaled_data[:, 0])) < 0.1, \\\"Column A mean is not close to 0\\\"  # Column A\\n\",\n",
    "    \"    assert np.abs(np.mean(scaled_data[:, 1])) < 0.1, \\\"Column B mean is not close to 0\\\"  # Column B\\n\",\n",
    "    \"    assert np.abs(np.std(scaled_data[:, 0]) - 1) < 0.1, \\\"Column A std is not close to 1\\\"\\n\",\n",
    "    \"    assert np.abs(np.std(scaled_data[:, 1]) - 1) < 0.1, \\\"Column B std is not close to 1\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scaling Function\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Combined Transformation Function\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"          A         B\\n\",\n",
    "      \"0 -1.147079 -1.605910\\n\",\n",
    "      \"1 -0.229416  0.229416\\n\",\n",
    "      \"2 -0.229416  0.229416\\n\",\n",
    "      \"3  1.605910  1.147079\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/tmp/ipykernel_11771/3361112369.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\\n\",\n",
    "      \"  if not np.issubdtype(df.dtypes[0], np.number):  # Check if data is numeric\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Imputation Function\\n\",\n",
    "    \"def impute_data(df, strategy='mean'):\\n\",\n",
    "    \"    for column in df.columns:\\n\",\n",
    "    \"        if df[column].isna().sum() == len(df):\\n\",\n",
    "    \"            df[column] = 0  # Or replace with df[column].median() or another placeholder\\n\",\n",
    "    \"    imputer = SimpleImputer(strategy=strategy)\\n\",\n",
    "    \"    return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scaling Function\\n\",\n",
    "    \"def scale_data(df):\\n\",\n",
    "    \"    scaler = StandardScaler()\\n\",\n",
    "    \"    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# DataFrame Validation Function\\n\",\n",
    "    \"def validate_dataframe(df):\\n\",\n",
    "    \"    if df.empty:\\n\",\n",
    "    \"        raise ValueError(\\\"DataFrame is empty\\\")\\n\",\n",
    "    \"    if not np.issubdtype(df.dtypes[0], np.number):  # Check if data is numeric\\n\",\n",
    "    \"        raise TypeError(\\\"DataFrame contains non-numeric data. Only numeric data is allowed.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Combined Transformation Function\\n\",\n",
    "    \"def transform_data(df, imputation_strategy='mean'):\\n\",\n",
    "    \"    validate_dataframe(df)\\n\",\n",
    "    \"    df = impute_data(df, strategy=imputation_strategy)\\n\",\n",
    "    \"    df = scale_data(df)\\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Example Usage\\n\",\n",
    "    \"data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]}\\n\",\n",
    "    \"df = pd.DataFrame(data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"transformed_df = transform_data(df, imputation_strategy='median')\\n\",\n",
    "    \"print(transformed_df)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
