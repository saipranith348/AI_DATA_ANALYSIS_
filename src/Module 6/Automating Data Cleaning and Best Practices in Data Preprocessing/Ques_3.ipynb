{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Data Preprocessing\n",
    "\n",
    "#### Always Explore & Visualize Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': 2,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['def validate_dataframe(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Validates the dataframe by checking for the necessary columns and correct data types.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe to validate.\\n',\n",
       "    '    \\n',\n",
       "    '    Returns:\\n',\n",
       "    '        bool: True if the dataframe is valid, raises ValueError otherwise.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    \"    required_columns = ['Age', 'Gender', 'Income']\\n\",\n",
       "    '    if not all(col in df.columns for col in required_columns):\\n',\n",
       "    '        raise ValueError(f\"Missing required columns: {\\', \\'.join(required_columns)}\")\\n',\n",
       "    '    \\n',\n",
       "    \"    if not np.issubdtype(df['Age'].dtype, np.number) or not np.issubdtype(df['Income'].dtype, np.number):\\n\",\n",
       "    '        raise ValueError(\"Columns \\'Age\\' and \\'Income\\' should be numeric.\")\\n',\n",
       "    '    \\n',\n",
       "    \"    if not np.issubdtype(df['Gender'].dtype, object):  # Change np.object to object\\n\",\n",
       "    '        raise ValueError(\"Column \\'Gender\\' should be categorical.\")\\n',\n",
       "    '\\n',\n",
       "    '    return True\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stderr',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['/tmp/ipykernel_13424/3320633278.py:44: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\\n',\n",
       "      \"  if not np.issubdtype(df['Gender'].dtype, np.object):\\n\"]},\n",
       "    {'ename': 'AttributeError',\n",
       "     'evalue': \"module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\",\n",
       "     'output_type': 'error',\n",
       "     'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m',\n",
       "      '\\x1b[0;31mAttributeError\\x1b[0m                            Traceback (most recent call last)',\n",
       "      'Cell \\x1b[0;32mIn[3], line 160\\x1b[0m\\n\\x1b[1;32m    157\\x1b[0m df \\x1b[38;5;241m=\\x1b[39m load_data()\\n\\x1b[1;32m    159\\x1b[0m \\x1b[38;5;66;03m# Apply preprocessing pipeline\\x1b[39;00m\\n\\x1b[0;32m--> 160\\x1b[0m preprocessed_data \\x1b[38;5;241m=\\x1b[39m \\x1b[43mapply_pipeline\\x1b[49m\\x1b[43m(\\x1b[49m\\x1b[43mdf\\x1b[49m\\x1b[43m)\\x1b[49m\\n\\x1b[1;32m    161\\x1b[0m \\x1b[38;5;28mprint\\x1b[39m(preprocessed_data)\\n',\n",
       "      'Cell \\x1b[0;32mIn[3], line 139\\x1b[0m, in \\x1b[0;36mapply_pipeline\\x1b[0;34m(df)\\x1b[0m\\n\\x1b[1;32m    129\\x1b[0m \\x1b[38;5;250m\\x1b[39m\\x1b[38;5;124;03m\"\"\"\\x1b[39;00m\\n\\x1b[1;32m    130\\x1b[0m \\x1b[38;5;124;03mApplies the preprocessing pipeline to the given dataframe.\\x1b[39;00m\\n\\x1b[1;32m    131\\x1b[0m \\n\\x1b[0;32m   (...)\\x1b[0m\\n\\x1b[1;32m    136\\x1b[0m \\x1b[38;5;124;03m    pd.DataFrame: The preprocessed dataframe.\\x1b[39;00m\\n\\x1b[1;32m    137\\x1b[0m \\x1b[38;5;124;03m\"\"\"\\x1b[39;00m\\n\\x1b[1;32m    138\\x1b[0m \\x1b[38;5;66;03m# Validate the dataframe\\x1b[39;00m\\n\\x1b[0;32m--> 139\\x1b[0m \\x1b[43mvalidate_dataframe\\x1b[49m\\x1b[43m(\\x1b[49m\\x1b[43mdf\\x1b[49m\\x1b[43m)\\x1b[49m\\n\\x1b[1;32m    141\\x1b[0m \\x1b[38;5;66;03m# Split the data into features and target (if applicable)\\x1b[39;00m\\n\\x1b[1;32m    142\\x1b[0m X \\x1b[38;5;241m=\\x1b[39m df\\x1b[38;5;241m.\\x1b[39mdrop(\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mIncome\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m, axis\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;241m1\\x1b[39m)  \\x1b[38;5;66;03m# Assuming \\'Income\\' is the target, adjust as needed\\x1b[39;00m\\n',\n",
       "      'Cell \\x1b[0;32mIn[3], line 44\\x1b[0m, in \\x1b[0;36mvalidate_dataframe\\x1b[0;34m(df)\\x1b[0m\\n\\x1b[1;32m     41\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m np\\x1b[38;5;241m.\\x1b[39missubdtype(df[\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mAge\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m]\\x1b[38;5;241m.\\x1b[39mdtype, np\\x1b[38;5;241m.\\x1b[39mnumber) \\x1b[38;5;129;01mor\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m np\\x1b[38;5;241m.\\x1b[39missubdtype(df[\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mIncome\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m]\\x1b[38;5;241m.\\x1b[39mdtype, np\\x1b[38;5;241m.\\x1b[39mnumber):\\n\\x1b[1;32m     42\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m \\x1b[38;5;167;01mValueError\\x1b[39;00m(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mColumns \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mAge\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m and \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mIncome\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m should be numeric.\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[0;32m---> 44\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m np\\x1b[38;5;241m.\\x1b[39missubdtype(df[\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mGender\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m]\\x1b[38;5;241m.\\x1b[39mdtype, \\x1b[43mnp\\x1b[49m\\x1b[38;5;241;43m.\\x1b[39;49m\\x1b[43mobject\\x1b[49m):\\n\\x1b[1;32m     45\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m \\x1b[38;5;167;01mValueError\\x1b[39;00m(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mColumn \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mGender\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m should be categorical.\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[1;32m     47\\x1b[0m \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mTrue\\x1b[39;00m\\n',\n",
       "      'File \\x1b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:324\\x1b[0m, in \\x1b[0;36m__getattr__\\x1b[0;34m(attr)\\x1b[0m\\n\\x1b[1;32m    319\\x1b[0m     warnings\\x1b[38;5;241m.\\x1b[39mwarn(\\n\\x1b[1;32m    320\\x1b[0m         \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mIn the future `np.\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mattr\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m` will be defined as the \\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\n\\x1b[1;32m    321\\x1b[0m         \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mcorresponding NumPy scalar.\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, \\x1b[38;5;167;01mFutureWarning\\x1b[39;00m, stacklevel\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;241m2\\x1b[39m)\\n\\x1b[1;32m    323\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m attr \\x1b[38;5;129;01min\\x1b[39;00m __former_attrs__:\\n\\x1b[0;32m--> 324\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m \\x1b[38;5;167;01mAttributeError\\x1b[39;00m(__former_attrs__[attr])\\n\\x1b[1;32m    326\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m attr \\x1b[38;5;241m==\\x1b[39m \\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124mtesting\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m:\\n\\x1b[1;32m    327\\x1b[0m     \\x1b[38;5;28;01mimport\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mnumpy\\x1b[39;00m\\x1b[38;5;21;01m.\\x1b[39;00m\\x1b[38;5;21;01mtesting\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mas\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mtesting\\x1b[39;00m\\n',\n",
       "      \"\\x1b[0;31mAttributeError\\x1b[0m: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\"]}],\n",
       "   'source': ['import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'from sklearn.preprocessing import StandardScaler, OneHotEncoder\\n',\n",
       "    'from sklearn.impute import SimpleImputer\\n',\n",
       "    'from sklearn.pipeline import Pipeline\\n',\n",
       "    'from sklearn.compose import ColumnTransformer\\n',\n",
       "    'from sklearn.model_selection import train_test_split\\n',\n",
       "    '\\n',\n",
       "    '# Step 1: Load a sample dataset\\n',\n",
       "    'def load_data():\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Load a sample dataset for preprocessing. The dataset contains both numerical and categorical columns.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        pd.DataFrame: The loaded dataset.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    # Example dataset: Replace this with your actual data loading step\\n',\n",
       "    '    data = {\\n',\n",
       "    \"        'Age': [25, np.nan, 30, 35, np.nan],\\n\",\n",
       "    \"        'Gender': ['M', 'F', 'M', 'F', 'M'],\\n\",\n",
       "    \"        'Income': [50000, 60000, 55000, np.nan, 70000]\\n\",\n",
       "    '    }\\n',\n",
       "    '    df = pd.DataFrame(data)\\n',\n",
       "    '    return df\\n',\n",
       "    '\\n',\n",
       "    '# Step 2: Check input dataframe\\n',\n",
       "    'def validate_dataframe(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Validates the dataframe by checking for the necessary columns and correct data types.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe to validate.\\n',\n",
       "    '    \\n',\n",
       "    '    Returns:\\n',\n",
       "    '        bool: True if the dataframe is valid, raises ValueError otherwise.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    \"    required_columns = ['Age', 'Gender', 'Income']\\n\",\n",
       "    '    if not all(col in df.columns for col in required_columns):\\n',\n",
       "    '        raise ValueError(f\"Missing required columns: {\\', \\'.join(required_columns)}\")\\n',\n",
       "    '    \\n',\n",
       "    \"    if not np.issubdtype(df['Age'].dtype, np.number) or not np.issubdtype(df['Income'].dtype, np.number):\\n\",\n",
       "    '        raise ValueError(\"Columns \\'Age\\' and \\'Income\\' should be numeric.\")\\n',\n",
       "    '    \\n',\n",
       "    \"    if not np.issubdtype(df['Gender'].dtype, np.object):\\n\",\n",
       "    '        raise ValueError(\"Column \\'Gender\\' should be categorical.\")\\n',\n",
       "    '\\n',\n",
       "    '    return True\\n',\n",
       "    '\\n',\n",
       "    '# Step 3: Imputation Function\\n',\n",
       "    'def impute_data(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Fills missing values in the dataframe using mean imputation for numerical columns.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe with missing values.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        pd.DataFrame: The dataframe with missing values imputed.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    \"    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\\n\",\n",
       "    \"    imputer = SimpleImputer(strategy='mean')\\n\",\n",
       "    '    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\\n',\n",
       "    '    return df\\n',\n",
       "    '\\n',\n",
       "    '# Step 4: Encoding Categorical Data\\n',\n",
       "    'def encode_categorical(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Encodes categorical columns using OneHotEncoder.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe with categorical columns.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        pd.DataFrame: The dataframe with encoded categorical columns.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    \"    # Check if 'Gender' column exists\\n\",\n",
       "    \"    if 'Gender' not in df.columns:\\n\",\n",
       "    '        raise ValueError(\"Column \\'Gender\\' is missing in the dataframe.\")\\n',\n",
       "    '    \\n',\n",
       "    \"    one_hot_encoder = OneHotEncoder(sparse=False, drop='first')\\n\",\n",
       "    \"    gender_encoded = one_hot_encoder.fit_transform(df[['Gender']])\\n\",\n",
       "    \"    gender_encoded_df = pd.DataFrame(gender_encoded, columns=one_hot_encoder.get_feature_names_out(['Gender']))\\n\",\n",
       "    \"    df = df.join(gender_encoded_df).drop('Gender', axis=1)\\n\",\n",
       "    '    return df\\n',\n",
       "    '\\n',\n",
       "    '# Step 5: Feature Scaling (Standardization)\\n',\n",
       "    'def scale_features(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Scales the numerical features of the dataframe using StandardScaler.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe with numerical columns to scale.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        pd.DataFrame: The dataframe with scaled features.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    \"    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\\n\",\n",
       "    '    scaler = StandardScaler()\\n',\n",
       "    '    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\\n',\n",
       "    '    return df\\n',\n",
       "    '\\n',\n",
       "    '# Step 6: Build a Preprocessing Pipeline\\n',\n",
       "    'def build_pipeline():\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Builds a preprocessing pipeline to impute missing values, encode categorical data, \\n',\n",
       "    '    and scale numerical features.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        sklearn.pipeline.Pipeline: The complete preprocessing pipeline.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    # Column transformer to apply different transformations on different columns\\n',\n",
       "    '    preprocessor = ColumnTransformer(\\n',\n",
       "    '        transformers=[\\n',\n",
       "    \"            ('num', SimpleImputer(strategy='mean'), ['Age', 'Income']),\\n\",\n",
       "    \"            ('cat', OneHotEncoder(sparse=False, drop='first'), ['Gender'])\\n\",\n",
       "    '        ]\\n',\n",
       "    '    )\\n',\n",
       "    '    \\n',\n",
       "    '    # Create a pipeline with preprocessing steps\\n',\n",
       "    '    pipeline = Pipeline(steps=[\\n',\n",
       "    \"        ('preprocessor', preprocessor),\\n\",\n",
       "    \"        ('scaler', StandardScaler())\\n\",\n",
       "    '    ])\\n',\n",
       "    '    \\n',\n",
       "    '    return pipeline\\n',\n",
       "    '\\n',\n",
       "    '# Step 7: Apply the Preprocessing Pipeline\\n',\n",
       "    'def apply_pipeline(df):\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    Applies the preprocessing pipeline to the given dataframe.\\n',\n",
       "    '\\n',\n",
       "    '    Args:\\n',\n",
       "    '        df (pd.DataFrame): The dataframe to preprocess.\\n',\n",
       "    '\\n',\n",
       "    '    Returns:\\n',\n",
       "    '        pd.DataFrame: The preprocessed dataframe.\\n',\n",
       "    '    \"\"\"\\n',\n",
       "    '    # Validate the dataframe\\n',\n",
       "    '    validate_dataframe(df)\\n',\n",
       "    '    \\n',\n",
       "    '    # Split the data into features and target (if applicable)\\n',\n",
       "    \"    X = df.drop('Income', axis=1)  # Assuming 'Income' is the target, adjust as needed\\n\",\n",
       "    \"    y = df['Income']\\n\",\n",
       "    '    \\n',\n",
       "    '    # Build and apply the pipeline\\n',\n",
       "    '    pipeline = build_pipeline()\\n',\n",
       "    '    X_transformed = pipeline.fit_transform(X)\\n',\n",
       "    '    \\n',\n",
       "    '    # Return the transformed data\\n',\n",
       "    \"    transformed_df = pd.DataFrame(X_transformed, columns=['Age', 'Gender_M'])\\n\",\n",
       "    \"    transformed_df['Income'] = y\\n\",\n",
       "    '    return transformed_df\\n',\n",
       "    '\\n',\n",
       "    '# Example usage\\n',\n",
       "    'if __name__ == \"__main__\":\\n',\n",
       "    '    # Load the data\\n',\n",
       "    '    df = load_data()\\n',\n",
       "    '    \\n',\n",
       "    '    # Apply preprocessing pipeline\\n',\n",
       "    '    preprocessed_data = apply_pipeline(df)\\n',\n",
       "    '    print(preprocessed_data)']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.10.12'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def validate_dataframe(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Validates the dataframe by checking for the necessary columns and correct data types.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe to validate.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        bool: True if the dataframe is valid, raises ValueError otherwise.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    required_columns = ['Age', 'Gender', 'Income']\\n\",\n",
    "    \"    if not all(col in df.columns for col in required_columns):\\n\",\n",
    "    \"        raise ValueError(f\\\"Missing required columns: {', '.join(required_columns)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.issubdtype(df['Age'].dtype, np.number) or not np.issubdtype(df['Income'].dtype, np.number):\\n\",\n",
    "    \"        raise ValueError(\\\"Columns 'Age' and 'Income' should be numeric.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.issubdtype(df['Gender'].dtype, object):  # Change np.object to object\\n\",\n",
    "    \"        raise ValueError(\\\"Column 'Gender' should be categorical.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return True\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/tmp/ipykernel_13424/3320633278.py:44: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\\n\",\n",
    "      \"  if not np.issubdtype(df['Gender'].dtype, np.object):\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"ename\": \"AttributeError\",\n",
    "     \"evalue\": \"module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "      \"\\u001b[0;31mAttributeError\\u001b[0m                            Traceback (most recent call last)\",\n",
    "      \"Cell \\u001b[0;32mIn[3], line 160\\u001b[0m\\n\\u001b[1;32m    157\\u001b[0m df \\u001b[38;5;241m=\\u001b[39m load_data()\\n\\u001b[1;32m    159\\u001b[0m \\u001b[38;5;66;03m# Apply preprocessing pipeline\\u001b[39;00m\\n\\u001b[0;32m--> 160\\u001b[0m preprocessed_data \\u001b[38;5;241m=\\u001b[39m \\u001b[43mapply_pipeline\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mdf\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    161\\u001b[0m \\u001b[38;5;28mprint\\u001b[39m(preprocessed_data)\\n\",\n",
    "      \"Cell \\u001b[0;32mIn[3], line 139\\u001b[0m, in \\u001b[0;36mapply_pipeline\\u001b[0;34m(df)\\u001b[0m\\n\\u001b[1;32m    129\\u001b[0m \\u001b[38;5;250m\\u001b[39m\\u001b[38;5;124;03m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    130\\u001b[0m \\u001b[38;5;124;03mApplies the preprocessing pipeline to the given dataframe.\\u001b[39;00m\\n\\u001b[1;32m    131\\u001b[0m \\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    136\\u001b[0m \\u001b[38;5;124;03m    pd.DataFrame: The preprocessed dataframe.\\u001b[39;00m\\n\\u001b[1;32m    137\\u001b[0m \\u001b[38;5;124;03m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    138\\u001b[0m \\u001b[38;5;66;03m# Validate the dataframe\\u001b[39;00m\\n\\u001b[0;32m--> 139\\u001b[0m \\u001b[43mvalidate_dataframe\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mdf\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    141\\u001b[0m \\u001b[38;5;66;03m# Split the data into features and target (if applicable)\\u001b[39;00m\\n\\u001b[1;32m    142\\u001b[0m X \\u001b[38;5;241m=\\u001b[39m df\\u001b[38;5;241m.\\u001b[39mdrop(\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mIncome\\u001b[39m\\u001b[38;5;124m'\\u001b[39m, axis\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;241m1\\u001b[39m)  \\u001b[38;5;66;03m# Assuming 'Income' is the target, adjust as needed\\u001b[39;00m\\n\",\n",
    "      \"Cell \\u001b[0;32mIn[3], line 44\\u001b[0m, in \\u001b[0;36mvalidate_dataframe\\u001b[0;34m(df)\\u001b[0m\\n\\u001b[1;32m     41\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m np\\u001b[38;5;241m.\\u001b[39missubdtype(df[\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mAge\\u001b[39m\\u001b[38;5;124m'\\u001b[39m]\\u001b[38;5;241m.\\u001b[39mdtype, np\\u001b[38;5;241m.\\u001b[39mnumber) \\u001b[38;5;129;01mor\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m np\\u001b[38;5;241m.\\u001b[39missubdtype(df[\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mIncome\\u001b[39m\\u001b[38;5;124m'\\u001b[39m]\\u001b[38;5;241m.\\u001b[39mdtype, np\\u001b[38;5;241m.\\u001b[39mnumber):\\n\\u001b[1;32m     42\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mValueError\\u001b[39;00m(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mColumns \\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mAge\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m and \\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mIncome\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m should be numeric.\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[0;32m---> 44\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m np\\u001b[38;5;241m.\\u001b[39missubdtype(df[\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mGender\\u001b[39m\\u001b[38;5;124m'\\u001b[39m]\\u001b[38;5;241m.\\u001b[39mdtype, \\u001b[43mnp\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mobject\\u001b[49m):\\n\\u001b[1;32m     45\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mValueError\\u001b[39;00m(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mColumn \\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mGender\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m should be categorical.\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[1;32m     47\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;01mTrue\\u001b[39;00m\\n\",\n",
    "      \"File \\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:324\\u001b[0m, in \\u001b[0;36m__getattr__\\u001b[0;34m(attr)\\u001b[0m\\n\\u001b[1;32m    319\\u001b[0m     warnings\\u001b[38;5;241m.\\u001b[39mwarn(\\n\\u001b[1;32m    320\\u001b[0m         \\u001b[38;5;124mf\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mIn the future `np.\\u001b[39m\\u001b[38;5;132;01m{\\u001b[39;00mattr\\u001b[38;5;132;01m}\\u001b[39;00m\\u001b[38;5;124m` will be defined as the \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    321\\u001b[0m         \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mcorresponding NumPy scalar.\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m, \\u001b[38;5;167;01mFutureWarning\\u001b[39;00m, stacklevel\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;241m2\\u001b[39m)\\n\\u001b[1;32m    323\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m attr \\u001b[38;5;129;01min\\u001b[39;00m __former_attrs__:\\n\\u001b[0;32m--> 324\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mAttributeError\\u001b[39;00m(__former_attrs__[attr])\\n\\u001b[1;32m    326\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m attr \\u001b[38;5;241m==\\u001b[39m \\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mtesting\\u001b[39m\\u001b[38;5;124m'\\u001b[39m:\\n\\u001b[1;32m    327\\u001b[0m     \\u001b[38;5;28;01mimport\\u001b[39;00m\\u001b[38;5;250m \\u001b[39m\\u001b[38;5;21;01mnumpy\\u001b[39;00m\\u001b[38;5;21;01m.\\u001b[39;00m\\u001b[38;5;21;01mtesting\\u001b[39;00m\\u001b[38;5;250m \\u001b[39m\\u001b[38;5;28;01mas\\u001b[39;00m\\u001b[38;5;250m \\u001b[39m\\u001b[38;5;21;01mtesting\\u001b[39;00m\\n\",\n",
    "      \"\\u001b[0;31mAttributeError\\u001b[0m: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler, OneHotEncoder\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.pipeline import Pipeline\\n\",\n",
    "    \"from sklearn.compose import ColumnTransformer\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 1: Load a sample dataset\\n\",\n",
    "    \"def load_data():\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Load a sample dataset for preprocessing. The dataset contains both numerical and categorical columns.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pd.DataFrame: The loaded dataset.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Example dataset: Replace this with your actual data loading step\\n\",\n",
    "    \"    data = {\\n\",\n",
    "    \"        'Age': [25, np.nan, 30, 35, np.nan],\\n\",\n",
    "    \"        'Gender': ['M', 'F', 'M', 'F', 'M'],\\n\",\n",
    "    \"        'Income': [50000, 60000, 55000, np.nan, 70000]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    df = pd.DataFrame(data)\\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 2: Check input dataframe\\n\",\n",
    "    \"def validate_dataframe(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Validates the dataframe by checking for the necessary columns and correct data types.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe to validate.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        bool: True if the dataframe is valid, raises ValueError otherwise.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    required_columns = ['Age', 'Gender', 'Income']\\n\",\n",
    "    \"    if not all(col in df.columns for col in required_columns):\\n\",\n",
    "    \"        raise ValueError(f\\\"Missing required columns: {', '.join(required_columns)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.issubdtype(df['Age'].dtype, np.number) or not np.issubdtype(df['Income'].dtype, np.number):\\n\",\n",
    "    \"        raise ValueError(\\\"Columns 'Age' and 'Income' should be numeric.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not np.issubdtype(df['Gender'].dtype, np.object):\\n\",\n",
    "    \"        raise ValueError(\\\"Column 'Gender' should be categorical.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 3: Imputation Function\\n\",\n",
    "    \"def impute_data(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Fills missing values in the dataframe using mean imputation for numerical columns.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe with missing values.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pd.DataFrame: The dataframe with missing values imputed.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\\n\",\n",
    "    \"    imputer = SimpleImputer(strategy='mean')\\n\",\n",
    "    \"    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 4: Encoding Categorical Data\\n\",\n",
    "    \"def encode_categorical(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Encodes categorical columns using OneHotEncoder.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe with categorical columns.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pd.DataFrame: The dataframe with encoded categorical columns.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Check if 'Gender' column exists\\n\",\n",
    "    \"    if 'Gender' not in df.columns:\\n\",\n",
    "    \"        raise ValueError(\\\"Column 'Gender' is missing in the dataframe.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    one_hot_encoder = OneHotEncoder(sparse=False, drop='first')\\n\",\n",
    "    \"    gender_encoded = one_hot_encoder.fit_transform(df[['Gender']])\\n\",\n",
    "    \"    gender_encoded_df = pd.DataFrame(gender_encoded, columns=one_hot_encoder.get_feature_names_out(['Gender']))\\n\",\n",
    "    \"    df = df.join(gender_encoded_df).drop('Gender', axis=1)\\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 5: Feature Scaling (Standardization)\\n\",\n",
    "    \"def scale_features(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Scales the numerical features of the dataframe using StandardScaler.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe with numerical columns to scale.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pd.DataFrame: The dataframe with scaled features.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\\n\",\n",
    "    \"    scaler = StandardScaler()\\n\",\n",
    "    \"    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 6: Build a Preprocessing Pipeline\\n\",\n",
    "    \"def build_pipeline():\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Builds a preprocessing pipeline to impute missing values, encode categorical data, \\n\",\n",
    "    \"    and scale numerical features.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        sklearn.pipeline.Pipeline: The complete preprocessing pipeline.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Column transformer to apply different transformations on different columns\\n\",\n",
    "    \"    preprocessor = ColumnTransformer(\\n\",\n",
    "    \"        transformers=[\\n\",\n",
    "    \"            ('num', SimpleImputer(strategy='mean'), ['Age', 'Income']),\\n\",\n",
    "    \"            ('cat', OneHotEncoder(sparse=False, drop='first'), ['Gender'])\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create a pipeline with preprocessing steps\\n\",\n",
    "    \"    pipeline = Pipeline(steps=[\\n\",\n",
    "    \"        ('preprocessor', preprocessor),\\n\",\n",
    "    \"        ('scaler', StandardScaler())\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 7: Apply the Preprocessing Pipeline\\n\",\n",
    "    \"def apply_pipeline(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Applies the preprocessing pipeline to the given dataframe.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        df (pd.DataFrame): The dataframe to preprocess.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pd.DataFrame: The preprocessed dataframe.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Validate the dataframe\\n\",\n",
    "    \"    validate_dataframe(df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Split the data into features and target (if applicable)\\n\",\n",
    "    \"    X = df.drop('Income', axis=1)  # Assuming 'Income' is the target, adjust as needed\\n\",\n",
    "    \"    y = df['Income']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Build and apply the pipeline\\n\",\n",
    "    \"    pipeline = build_pipeline()\\n\",\n",
    "    \"    X_transformed = pipeline.fit_transform(X)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Return the transformed data\\n\",\n",
    "    \"    transformed_df = pd.DataFrame(X_transformed, columns=['Age', 'Gender_M'])\\n\",\n",
    "    \"    transformed_df['Income'] = y\\n\",\n",
    "    \"    return transformed_df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Example usage\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    # Load the data\\n\",\n",
    "    \"    df = load_data()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Apply preprocessing pipeline\\n\",\n",
    "    \"    preprocessed_data = apply_pipeline(df)\\n\",\n",
    "    \"    print(preprocessed_data)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing & Inconsistent Data Before Applying ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Drop Missing Values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 5: Fill Missing Values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 6: Handling Outliers with Capping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Right Scaling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Min-Max Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 8: Robust Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 9: MaxAbs Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Track of Data Transformations for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10: Log Data Preprocessing Steps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 11: Store Transformation Parameters\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
