{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "    Task: Basic Pipeline with Scaling\n",
    "1. Objective: Create a pipeline that scales numerical features in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset with Pandas.\n",
    "    - Define a pipeline using Pipeline from sklearn.pipeline .\n",
    "    - Use StandardScaler to scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Automating Data Cleaning in Python']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'vscode': {'languageId': 'plaintext'}},\n",
       "   'source': ['    Task: Basic Pipeline with Scaling\\n',\n",
       "    '1. Objective: Create a pipeline that scales numerical features in a dataset.\\n',\n",
       "    '2. Steps:\\n',\n",
       "    '    - Load a sample dataset with Pandas.\\n',\n",
       "    '    - Define a pipeline using Pipeline from sklearn.pipeline .\\n',\n",
       "    '    - Use StandardScaler to scale features.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['Processed Data (Imputed and Scaled):\\n',\n",
       "      '   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\\n',\n",
       "      '0           0.000000          1.019004          -1.340227         -1.315444\\n',\n",
       "      '1          -1.152203         -0.131979          -1.340227         -1.315444\\n',\n",
       "      '2          -1.395201          0.328414          -1.397064         -1.315444\\n',\n",
       "      '3          -1.516700          0.098217          -1.283389         -1.315444\\n',\n",
       "      '4          -1.030704          1.249201          -1.340227         -1.315444\\n']},\n",
       "    {'name': 'stderr',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\\n',\n",
       "      '                             [-k TESTNAMEPATTERNS]\\n',\n",
       "      '                             [tests ...]\\n',\n",
       "      \"ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/vscode/.local/share/jupyter/runtime/kernel-v3afbdb9fd34af9c3e2bb4069e45a0b38baf1edef7.json'\\n\"]},\n",
       "    {'ename': 'SystemExit',\n",
       "     'evalue': '2',\n",
       "     'output_type': 'error',\n",
       "     'traceback': ['An exception has occurred, use %tb to see the full traceback.\\n',\n",
       "      '\\x1b[0;31mSystemExit\\x1b[0m\\x1b[0;31m:\\x1b[0m 2\\n']},\n",
       "    {'name': 'stderr',\n",
       "     'output_type': 'stream',\n",
       "     'text': [\"/home/vscode/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\\n\",\n",
       "      '  warn(\"To exit: use \\'exit\\', \\'quit\\', or Ctrl-D.\", stacklevel=1)\\n']}],\n",
       "   'source': ['# Write your code from here\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'from sklearn.preprocessing import StandardScaler\\n',\n",
       "    'from sklearn.impute import SimpleImputer\\n',\n",
       "    'from sklearn.pipeline import Pipeline\\n',\n",
       "    'from sklearn.model_selection import train_test_split\\n',\n",
       "    'import unittest\\n',\n",
       "    '\\n',\n",
       "    '# --- Helper Functions ---\\n',\n",
       "    'def check_empty_dataframe(df):\\n',\n",
       "    '    \"\"\"Check if the DataFrame is empty.\"\"\"\\n',\n",
       "    '    if df.empty:\\n',\n",
       "    '        raise ValueError(\"The input dataset is empty\")\\n',\n",
       "    '\\n',\n",
       "    'def create_pipeline(scaling=True, imputation=True):\\n',\n",
       "    '    \"\"\"Create a preprocessing pipeline that includes scaling and/or imputation.\"\"\"\\n',\n",
       "    '    steps = []\\n',\n",
       "    '    if imputation:\\n',\n",
       "    \"        steps.append(('imputer', SimpleImputer(strategy='mean')))\\n\",\n",
       "    '    if scaling:\\n',\n",
       "    \"        steps.append(('scaler', StandardScaler()))\\n\",\n",
       "    '    return Pipeline(steps)\\n',\n",
       "    '\\n',\n",
       "    '# --- Example Dataset ---\\n',\n",
       "    '# Load Iris dataset\\n',\n",
       "    'from sklearn.datasets import load_iris\\n',\n",
       "    'data = load_iris()\\n',\n",
       "    'df = pd.DataFrame(data.data, columns=data.feature_names)\\n',\n",
       "    '\\n',\n",
       "    '# Introduce missing values for demonstration\\n',\n",
       "    'df.iloc[0, 0] = np.nan  # Missing value in Feature1\\n',\n",
       "    '\\n',\n",
       "    '# --- Data Preprocessing ---\\n',\n",
       "    '# Check if dataset is empty before processing\\n',\n",
       "    'check_empty_dataframe(df)\\n',\n",
       "    '\\n',\n",
       "    '# Create the preprocessing pipeline (with both scaling and imputation)\\n',\n",
       "    'pipeline = create_pipeline(scaling=True, imputation=True)\\n',\n",
       "    '\\n',\n",
       "    '# Fit and transform the dataset using the pipeline\\n',\n",
       "    'processed_data = pipeline.fit_transform(df)\\n',\n",
       "    '\\n',\n",
       "    '# Convert the processed data back to DataFrame\\n',\n",
       "    'processed_df = pd.DataFrame(processed_data, columns=df.columns)\\n',\n",
       "    '\\n',\n",
       "    '# Show the processed dataset\\n',\n",
       "    'print(\"Processed Data (Imputed and Scaled):\")\\n',\n",
       "    'print(processed_df.head())\\n',\n",
       "    '\\n',\n",
       "    '# --- Unit Tests ---\\n',\n",
       "    'class TestDataPipeline(unittest.TestCase):\\n',\n",
       "    '    def setUp(self):\\n',\n",
       "    '        \"\"\"Prepare a sample dataset with missing values for testing.\"\"\"\\n',\n",
       "    '        self.data = load_iris()\\n',\n",
       "    '        self.df = pd.DataFrame(self.data.data, columns=self.data.feature_names)\\n',\n",
       "    '        self.df.iloc[0, 0] = np.nan  # Introduce a missing value\\n',\n",
       "    '\\n',\n",
       "    '    def test_scaling_pipeline(self):\\n',\n",
       "    '        \"\"\"Test if the scaling pipeline works correctly.\"\"\"\\n',\n",
       "    '        pipeline = create_pipeline(scaling=True, imputation=False)\\n',\n",
       "    '        scaled_data = pipeline.fit_transform(self.df)\\n',\n",
       "    '        self.assertEqual(scaled_data.shape, self.df.shape)  # Check if the shape remains the same\\n',\n",
       "    '\\n',\n",
       "    '    def test_imputation_pipeline(self):\\n',\n",
       "    '        \"\"\"Test if the imputation pipeline works correctly.\"\"\"\\n',\n",
       "    '        pipeline = create_pipeline(scaling=False, imputation=True)\\n',\n",
       "    '        imputed_data = pipeline.fit_transform(self.df)\\n',\n",
       "    '        self.assertFalse(np.any(np.isnan(imputed_data)))  # Check if NaNs are filled\\n',\n",
       "    '\\n',\n",
       "    '    def test_empty_dataframe(self):\\n',\n",
       "    '        \"\"\"Test if an error is raised when an empty dataframe is provided.\"\"\"\\n',\n",
       "    '        empty_df = pd.DataFrame()\\n',\n",
       "    '        with self.assertRaises(ValueError):\\n',\n",
       "    '            check_empty_dataframe(empty_df)\\n',\n",
       "    '\\n',\n",
       "    '# Run the unit tests\\n',\n",
       "    \"if __name__ == '__main__':\\n\",\n",
       "    '    unittest.main()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['    Task: Pipeline with Imputation\\n',\n",
       "    '1. Objective: Automate data cleaning by handling missing values.\\n',\n",
       "    '2. Steps:\\n',\n",
       "    '    - Load a dataset with missing values.\\n',\n",
       "    '    - Define a pipeline to use SimpleImputer for filling missing values.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 4,\n",
       "   'metadata': {},\n",
       "   'outputs': [{'name': 'stdout',\n",
       "     'output_type': 'stream',\n",
       "     'text': ['   Feature1  Feature2\\n',\n",
       "      '0      1.00  3.666667\\n',\n",
       "      '1      2.00  2.000000\\n',\n",
       "      '2      3.00  3.666667\\n',\n",
       "      '3      2.75  4.000000\\n',\n",
       "      '4      5.00  5.000000\\n']}],\n",
       "   'source': ['# Write your code from here\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'from sklearn.impute import SimpleImputer\\n',\n",
       "    'from sklearn.pipeline import Pipeline\\n',\n",
       "    '\\n',\n",
       "    '# Step 1: Load a dataset with missing values\\n',\n",
       "    '# Creating a sample dataset with missing values for illustration\\n',\n",
       "    \"data = {'Feature1': [1, 2, 3, None, 5],\\n\",\n",
       "    \"        'Feature2': [None, 2, None, 4, 5]}\\n\",\n",
       "    '\\n',\n",
       "    'df = pd.DataFrame(data)\\n',\n",
       "    '\\n',\n",
       "    '# Step 2: Define a pipeline\\n',\n",
       "    '# Here, we will apply SimpleImputer to fill missing values with the mean\\n',\n",
       "    'pipeline = Pipeline(steps=[\\n',\n",
       "    \"    ('imputer', SimpleImputer(strategy='mean'))\\n\",\n",
       "    '])\\n',\n",
       "    '\\n',\n",
       "    '# Step 3: Fit and transform the data using the pipeline\\n',\n",
       "    'imputed_data = pipeline.fit_transform(df)\\n',\n",
       "    '\\n',\n",
       "    '# Step 4: Show the imputed data\\n',\n",
       "    'imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\\n',\n",
       "    'print(imputed_df)']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.10.12'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Automating Data Cleaning in Python\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"vscode\": {\n",
    "     \"languageId\": \"plaintext\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"    Task: Basic Pipeline with Scaling\\n\",\n",
    "    \"1. Objective: Create a pipeline that scales numerical features in a dataset.\\n\",\n",
    "    \"2. Steps:\\n\",\n",
    "    \"    - Load a sample dataset with Pandas.\\n\",\n",
    "    \"    - Define a pipeline using Pipeline from sklearn.pipeline .\\n\",\n",
    "    \"    - Use StandardScaler to scale features.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Processed Data (Imputed and Scaled):\\n\",\n",
    "      \"   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\\n\",\n",
    "      \"0           0.000000          1.019004          -1.340227         -1.315444\\n\",\n",
    "      \"1          -1.152203         -0.131979          -1.340227         -1.315444\\n\",\n",
    "      \"2          -1.395201          0.328414          -1.397064         -1.315444\\n\",\n",
    "      \"3          -1.516700          0.098217          -1.283389         -1.315444\\n\",\n",
    "      \"4          -1.030704          1.249201          -1.340227         -1.315444\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\\n\",\n",
    "      \"                             [-k TESTNAMEPATTERNS]\\n\",\n",
    "      \"                             [tests ...]\\n\",\n",
    "      \"ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/vscode/.local/share/jupyter/runtime/kernel-v3afbdb9fd34af9c3e2bb4069e45a0b38baf1edef7.json'\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"ename\": \"SystemExit\",\n",
    "     \"evalue\": \"2\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"An exception has occurred, use %tb to see the full traceback.\\n\",\n",
    "      \"\\u001b[0;31mSystemExit\\u001b[0m\\u001b[0;31m:\\u001b[0m 2\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/vscode/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\\n\",\n",
    "      \"  warn(\\\"To exit: use 'exit', 'quit', or Ctrl-D.\\\", stacklevel=1)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Write your code from here\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.pipeline import Pipeline\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"import unittest\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Helper Functions ---\\n\",\n",
    "    \"def check_empty_dataframe(df):\\n\",\n",
    "    \"    \\\"\\\"\\\"Check if the DataFrame is empty.\\\"\\\"\\\"\\n\",\n",
    "    \"    if df.empty:\\n\",\n",
    "    \"        raise ValueError(\\\"The input dataset is empty\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_pipeline(scaling=True, imputation=True):\\n\",\n",
    "    \"    \\\"\\\"\\\"Create a preprocessing pipeline that includes scaling and/or imputation.\\\"\\\"\\\"\\n\",\n",
    "    \"    steps = []\\n\",\n",
    "    \"    if imputation:\\n\",\n",
    "    \"        steps.append(('imputer', SimpleImputer(strategy='mean')))\\n\",\n",
    "    \"    if scaling:\\n\",\n",
    "    \"        steps.append(('scaler', StandardScaler()))\\n\",\n",
    "    \"    return Pipeline(steps)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Example Dataset ---\\n\",\n",
    "    \"# Load Iris dataset\\n\",\n",
    "    \"from sklearn.datasets import load_iris\\n\",\n",
    "    \"data = load_iris()\\n\",\n",
    "    \"df = pd.DataFrame(data.data, columns=data.feature_names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Introduce missing values for demonstration\\n\",\n",
    "    \"df.iloc[0, 0] = np.nan  # Missing value in Feature1\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Data Preprocessing ---\\n\",\n",
    "    \"# Check if dataset is empty before processing\\n\",\n",
    "    \"check_empty_dataframe(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the preprocessing pipeline (with both scaling and imputation)\\n\",\n",
    "    \"pipeline = create_pipeline(scaling=True, imputation=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fit and transform the dataset using the pipeline\\n\",\n",
    "    \"processed_data = pipeline.fit_transform(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert the processed data back to DataFrame\\n\",\n",
    "    \"processed_df = pd.DataFrame(processed_data, columns=df.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show the processed dataset\\n\",\n",
    "    \"print(\\\"Processed Data (Imputed and Scaled):\\\")\\n\",\n",
    "    \"print(processed_df.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Unit Tests ---\\n\",\n",
    "    \"class TestDataPipeline(unittest.TestCase):\\n\",\n",
    "    \"    def setUp(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Prepare a sample dataset with missing values for testing.\\\"\\\"\\\"\\n\",\n",
    "    \"        self.data = load_iris()\\n\",\n",
    "    \"        self.df = pd.DataFrame(self.data.data, columns=self.data.feature_names)\\n\",\n",
    "    \"        self.df.iloc[0, 0] = np.nan  # Introduce a missing value\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def test_scaling_pipeline(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Test if the scaling pipeline works correctly.\\\"\\\"\\\"\\n\",\n",
    "    \"        pipeline = create_pipeline(scaling=True, imputation=False)\\n\",\n",
    "    \"        scaled_data = pipeline.fit_transform(self.df)\\n\",\n",
    "    \"        self.assertEqual(scaled_data.shape, self.df.shape)  # Check if the shape remains the same\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def test_imputation_pipeline(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Test if the imputation pipeline works correctly.\\\"\\\"\\\"\\n\",\n",
    "    \"        pipeline = create_pipeline(scaling=False, imputation=True)\\n\",\n",
    "    \"        imputed_data = pipeline.fit_transform(self.df)\\n\",\n",
    "    \"        self.assertFalse(np.any(np.isnan(imputed_data)))  # Check if NaNs are filled\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def test_empty_dataframe(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Test if an error is raised when an empty dataframe is provided.\\\"\\\"\\\"\\n\",\n",
    "    \"        empty_df = pd.DataFrame()\\n\",\n",
    "    \"        with self.assertRaises(ValueError):\\n\",\n",
    "    \"            check_empty_dataframe(empty_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run the unit tests\\n\",\n",
    "    \"if __name__ == '__main__':\\n\",\n",
    "    \"    unittest.main()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Task: Pipeline with Imputation\\n\",\n",
    "    \"1. Objective: Automate data cleaning by handling missing values.\\n\",\n",
    "    \"2. Steps:\\n\",\n",
    "    \"    - Load a dataset with missing values.\\n\",\n",
    "    \"    - Define a pipeline to use SimpleImputer for filling missing values.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"   Feature1  Feature2\\n\",\n",
    "      \"0      1.00  3.666667\\n\",\n",
    "      \"1      2.00  2.000000\\n\",\n",
    "      \"2      3.00  3.666667\\n\",\n",
    "      \"3      2.75  4.000000\\n\",\n",
    "      \"4      5.00  5.000000\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Write your code from here\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.pipeline import Pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 1: Load a dataset with missing values\\n\",\n",
    "    \"# Creating a sample dataset with missing values for illustration\\n\",\n",
    "    \"data = {'Feature1': [1, 2, 3, None, 5],\\n\",\n",
    "    \"        'Feature2': [None, 2, None, 4, 5]}\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = pd.DataFrame(data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 2: Define a pipeline\\n\",\n",
    "    \"# Here, we will apply SimpleImputer to fill missing values with the mean\\n\",\n",
    "    \"pipeline = Pipeline(steps=[\\n\",\n",
    "    \"    ('imputer', SimpleImputer(strategy='mean'))\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 3: Fit and transform the data using the pipeline\\n\",\n",
    "    \"imputed_data = pipeline.fit_transform(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 4: Show the imputed data\\n\",\n",
    "    \"imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\\n\",\n",
    "    \"print(imputed_df)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Pipeline with Imputation\n",
    "1. Objective: Automate data cleaning by handling missing values.\n",
    "2. Steps:\n",
    "    - Load a dataset with missing values.\n",
    "    - Define a pipeline to use SimpleImputer for filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
